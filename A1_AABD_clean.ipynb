{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import plotly.express as px # plotting geo data\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\", header=0)\n",
    "data = data.drop(columns=['is_promoted','sticker','price_drop_date'])\n",
    "\n",
    "train, test = train_test_split(data.sort_values('added_time'),test_size=0.2, shuffle=False)\n",
    "\n",
    "train = train.reset_index()\n",
    "train['energy_label'] = train['energy_label'].astype('category')\n",
    "train['new_building'] = train['new_building'].astype('bool')\n",
    "train['postcode'] = train['postcode'].astype('category')\n",
    "# train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = round(train.isna().sum()/len(train)*100,2)\n",
    "missing_checker = train.isna()*1\n",
    "# missing_checker = missing_checker.drop(columns=missing_values.index[(missing_values>30) | (missing_values==0)].tolist()).drop(columns='energy_label').reset_index()\n",
    "missing_checker = missing_checker.drop(columns=missing_values.index[missing_values==0].tolist()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bedrooms_cat'] = pd.cut(train['bedrooms'], bins=[-1,0,1,2,3,4,5,6,float('inf')], labels=['0','1','2','3','4','5','6','7+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_map = {\n",
    "    'Apartments & Flats': [\n",
    "        'Appartement', 'Gelijkvloers app.', 'Duplex', 'Triplex', 'Dakappartement',\n",
    "        'Penthouse', 'Serviceflat', 'Assistentie-appartement', 'Studio', 'Studio met slaaphoek', \n",
    "        'App. vrij beroep', 'Appartementsgebouw'\n",
    "    ],\n",
    "    'Single-Family Houses': [\n",
    "        'Eengezinswoning', 'Woning', 'Villa', 'Villa-landhuis', 'Moderne villa',\n",
    "        'Cottage', 'Bungalow', 'Koppelwoning', 'Koppelvilla', 'Hoekwoning', 'Rijwoning', 'Bel-Ã©tage', 'Burgerswoning'\n",
    "    ],\n",
    "    'Historical & Luxurious Homes': [\n",
    "        'Herenhuis', 'Herenwoning', 'Uitzonderlijke woning', 'Kasteel', 'Pastorijwoning'\n",
    "    ],\n",
    "    'Farm & Rural Houses': [\n",
    "        'Hoeve', 'Boerderij', 'Fermette', 'Chalet'\n",
    "    ],\n",
    "    'Mixed-Use & Unique Properties': [\n",
    "        'Gemengd gebruik', 'Arbeiderswoning', 'Kangoeroewoning', 'Woonboot', 'Loft',\n",
    "        'Split-level', 'Patio woning', 'Buitenverblijf', 'Vakantiewoning'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to categorize houses\n",
    "def categorize_house(house_type):\n",
    "    for category, types in house_map.items():\n",
    "        if house_type in types:\n",
    "            return category\n",
    "    return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['house_type'] = train['subtype'].apply(categorize_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_subtype = train.groupby('bedrooms_cat', observed=False)['subtype'].apply(lambda x: x.value_counts().idxmax())\n",
    "train['subtype']=train.groupby('bedrooms_cat', observed=False)['subtype'].transform(lambda x: x.fillna(most_frequent_subtype[x.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_lookup=train.groupby('postcode', observed=False)[['lat','lon']].mean().dropna().reset_index()\n",
    "lat_lon_lookup.columns = ['postcode','lat_1','lon_1']\n",
    "lat_lon_lookup['postcode'] = lat_lon_lookup['postcode'].astype('category')\n",
    "\n",
    "postcode_list = pd.read_csv(\"BE.txt\", sep=\"\\t\", header=None)[[1,9,10]]\n",
    "postcode_list.columns = ['postcode','lat_2','lon_2']\n",
    "postcode_list['postcode']=postcode_list['postcode'].astype('category')\n",
    "postcode_list = postcode_list.groupby('postcode', observed=False)[['lat_2','lon_2']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(lat_lon_lookup, on=['postcode'], how='left')\n",
    "train = train.merge(postcode_list, on=['postcode'], how='left')\n",
    "train['lat'] = train['lat'].fillna(train['lat_1']).fillna(train['lat_2'])\n",
    "train['lon'] = train['lon'].fillna(train['lon_1']).fillna(train['lon_2'])\n",
    "train = train.drop(columns=['lat_1','lat_2','lon_1','lon_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_geo = EllipticEnvelope(contamination=0.0002, support_fraction=0.9)\n",
    "clf_geo.fit(train[['lat','lon']])\n",
    "outliers_geo = clf_geo.predict(train[['lat','lon']])\n",
    "\n",
    "train['lat'] = train['lat'].where(outliers_geo==1, np.nan)\n",
    "train['lon'] = train['lon'].where(outliers_geo==1, np.nan)\n",
    "\n",
    "lat_lon_lookup=train.groupby('postcode', observed=False)[['lat','lon']].mean().dropna().reset_index()\n",
    "lat_lon_lookup.columns = ['postcode','lat_1','lon_1']\n",
    "\n",
    "train = train.merge(lat_lon_lookup, on=['postcode'], how='left')\n",
    "train = train.merge(postcode_list, on=['postcode'], how='left')\n",
    "train['lat'] = train['lat'].fillna(train['lat_1']).fillna(train['lat_2'])\n",
    "train['lon'] = train['lon'].fillna(train['lon_1']).fillna(train['lon_2'])\n",
    "train = train.drop(columns=['lat_1','lat_2','lon_1','lon_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.scatter_geo(train, lat='lat', lon='lon', scope='europe')\n",
    "# fig.update_geos(showcountries=True, showcoastlines=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350.0\n"
     ]
    }
   ],
   "source": [
    "clf_area = EllipticEnvelope(contamination=0.0002, support_fraction=0.9)\n",
    "outliers_area = clf_area.fit_predict(train[['area']].dropna())\n",
    "train['area'] = train['area'].where(~train['id'].isin(train[['area','id']].dropna()[outliers_area==-1]['id']), np.nan)\n",
    "print(train['area'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_bed_area_lookup = train.groupby(['bedrooms_cat','subtype'], observed=False)['area'].median().dropna().reset_index()\n",
    "sub_bed_area_lookup.columns = ['bedrooms_cat','subtype', 'area_1']\n",
    "bed_ht_area_lookup = train.groupby(['bedrooms_cat', 'house_type'], observed=False)['area'].median().dropna().reset_index()\n",
    "bed_ht_area_lookup.columns = ['bedrooms_cat','house_type', 'area_2']\n",
    "bed_area_lookup = train.groupby(['bedrooms_cat'], observed=False)['area'].median().dropna().reset_index()\n",
    "bed_area_lookup.columns = ['bedrooms_cat', 'area_3']\n",
    "\n",
    "train = train.merge(sub_bed_area_lookup, on=['bedrooms_cat','subtype'], how='left')\n",
    "train = train.merge(bed_ht_area_lookup, on=['bedrooms_cat','house_type'], how='left')\n",
    "train = train.merge(bed_area_lookup, on=['bedrooms_cat'], how='left')\n",
    "train['area'] = train['area'].fillna(train['area_1']).fillna(train['area_2']).fillna(train['area_3'])\n",
    "train = train.drop(columns=['area_1','area_2','area_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_lookup = train.groupby(['energy_label','province'], observed=False)['energy_value'].median().dropna().reset_index()\n",
    "el_lookup.columns = ['energy_label', 'province', 'energy_value_1']\n",
    "\n",
    "train = train.merge(el_lookup, on=['energy_label', 'province'], how='left')\n",
    "train['energy_value'] = train['energy_value'].fillna(train['energy_value_1'])\n",
    "train = train.drop(columns='energy_value_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_imputer = KNNImputer(n_neighbors=10, weights='distance')\n",
    "imputed_data = ev_imputer.fit_transform(train[['energy_value','area','is_appartment','new_building', 'lat','lon']])\n",
    "# df_imputed = pd.DataFrame(imputed_data)\n",
    "train['energy_value']= pd.DataFrame(imputed_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(x=train['energy_value'],y=train['area'],c=missing_checker['energy_value'])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.xlim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['advertiser'] = train['advertiser'].fillna('Other')\n",
    "train['advertiser'] = train['advertiser'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_checker.columns = ['area_miss', 'lat_miss', 'lon_miss', 'advertiser_miss', 'subtype_miss', 'energy_value_miss', 'energy_label_miss']\n",
    "missing_checker = (missing_checker==1)\n",
    "train = pd.concat([train, missing_checker], axis=1)\n",
    "train['house_type'] = train['house_type'].astype('category')\n",
    "train['province']=train['province'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = train[['is_appartment','area','lat','lon','foto_amount','energy_value','house_type']].copy(),train['price'].copy()\n",
    "\n",
    "# X_train_encoded = pd.get_dummies(X_train, columns=['house_type'])\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_encoded[['area','lat','lon','energy_value','foto_amount']] = scaler.fit_transform(X_train_encoded[['area','lat','lon','energy_value','foto_amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_KNN = []\n",
    "# for i in range(2,60,2):\n",
    "#     neigh_model = KNeighborsRegressor(n_neighbors=i, weights='distance')\n",
    "#     scores_KNN.append(cross_val_score(neigh_model, X_train_encoded, y_train, cv=5, scoring='neg_mean_absolute_percentage_error')*-1)\n",
    "\n",
    "# scores_KNN = pd.DataFrame(scores_KNN)\n",
    "# plt.scatter((scores_KNN.index+1)*2, scores_KNN.apply(np.mean, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neigh_model_final = KNeighborsRegressor(n_neighbors=14, weights='distance')\n",
    "# neigh_model_final.fit(X_train_encoded,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train.drop(columns=['added_time','postcode','energy_label','subtype','bedrooms','id','index','price']),train['price'], shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "dval = xgb.DMatrix(X_val,label=y_val, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "evallist = [(dval, 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0]\\tval-rmse:114558.26176200545160100'"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_xgb = {'max_depth': 6, 'eta': 0.1, 'objective': 'reg:squarederror', 'reg_lambda':10, 'reg_alpha':10,}\n",
    "\n",
    "xgb_regressor = xgb.train(\n",
    "    params=param_xgb,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=500\n",
    ")\n",
    "xgb_regressor.eval_set([(dval,'val')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.drop(columns=['added_time','postcode','energy_label','subtype','bedrooms','id','index','price']).copy(),train['price'].copy()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "\n",
    "param_xgb = {'max_depth': 6, 'eta': 0.1, 'objective': 'reg:squarederror', 'reg_lambda':10, 'reg_alpha':10,}\n",
    "\n",
    "xgb_regressor_final = xgb.train(\n",
    "    params=param_xgb,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv(\"test.csv\", header=0)\n",
    "test = test.reset_index()\n",
    "# test = test.drop(columns=['is_promoted','sticker','price_drop_date'])\n",
    "test['energy_label'] = test['energy_label'].astype('category')\n",
    "test['new_building'] = test['new_building'].astype('bool')\n",
    "test['postcode'] = test['postcode'].astype('category')\n",
    "\n",
    "test['bedrooms_cat'] = pd.cut(test['bedrooms'], bins=[-1,0,1,2,3,4,5,6,float('inf')], labels=['0','1','2','3','4','5','6','7+'])\n",
    "test['house_type'] = test['subtype'].apply(categorize_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = round(test.isna().sum()/len(test)*100,2)\n",
    "missing_checker = test.isna()*1\n",
    "# missing_checker = missing_checker.drop(columns=missing_values.index[(missing_values>30) | (missing_values==0)].tolist()).drop(columns='energy_label').reset_index()\n",
    "missing_checker = missing_checker.drop(columns=missing_values.index[missing_values==0].tolist()).reset_index(drop=True)\n",
    "\n",
    "missing_checker.columns = ['area_miss', 'lat_miss', 'lon_miss', 'advertiser_miss', 'subtype_miss', 'energy_value_miss', 'energy_label_miss']\n",
    "missing_checker = (missing_checker==1)\n",
    "test = pd.concat([test, missing_checker], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['advertiser'] = test['advertiser'].fillna('Other')\n",
    "test['advertiser'] = test['advertiser'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['subtype']=test.groupby('bedrooms_cat', observed='False')['subtype'].transform(lambda x: x.fillna(most_frequent_subtype[x.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(lat_lon_lookup, on=['postcode'], how='left')\n",
    "test = test.merge(postcode_list, on=['postcode'], how='left')\n",
    "test['lat'] = test['lat'].fillna(test['lat_1']).fillna(test['lat_2'])\n",
    "test['lon'] = test['lon'].fillna(test['lon_1']).fillna(test['lon_2'])\n",
    "\n",
    "outliers_geo_test = clf_geo.predict(test[['lat','lon']])\n",
    "\n",
    "test['lat'] = test['lat'].where(outliers_geo_test==1, np.nan)\n",
    "test['lon'] = test['lon'].where(outliers_geo_test==1, np.nan)\n",
    "\n",
    "test['lat'] = test['lat'].fillna(test['lat_1']).fillna(test['lat_2'])\n",
    "test['lon'] = test['lon'].fillna(test['lon_1']).fillna(test['lon_2'])\n",
    "\n",
    "test = test.drop(columns=['lat_1','lat_2','lon_1','lon_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_area = clf_area.predict(test[['area']].dropna())\n",
    "test['area'] = test['area'].where(~test['id'].isin(test[['area','id']].dropna()[outliers_area==-1]['id']), np.nan)\n",
    "\n",
    "test = test.merge(sub_bed_area_lookup, on=['bedrooms_cat','subtype'], how='left')\n",
    "test = test.merge(bed_ht_area_lookup, on=['bedrooms_cat','house_type'], how='left')\n",
    "test = test.merge(bed_area_lookup, on=['bedrooms_cat'], how='left')\n",
    "test['area'] = test['area'].fillna(test['area_1']).fillna(test['area_2']).fillna(test['area_3'])\n",
    "test = test.drop(columns=['area_1','area_2','area_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(el_lookup, on=['energy_label','province'], how='left')\n",
    "test['energy_value'] = test['energy_value'].fillna(test['energy_value_1'])\n",
    "test = test.drop(columns='energy_value_1')\n",
    "\n",
    "imputed_data = ev_imputer.fit_transform(test[['energy_value','area','is_appartment','new_building', 'lat','lon']])\n",
    "test['energy_value']= pd.DataFrame(imputed_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['house_type'] = test['house_type'].astype('category')\n",
    "test['province']=test['province'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = test[['is_appartment','area','lat','lon','foto_amount','energy_value','house_type']].copy()\n",
    "\n",
    "# X_test_encoded = pd.get_dummies(X_test, columns=['house_type'])\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_test_encoded[['area','lat','lon','energy_value','foto_amount']] = scaler.fit_transform(X_test_encoded[['area','lat','lon','energy_value','foto_amount']])\n",
    "# X_test_encoded.isna().apply(sum)\n",
    "# y_test = test['price'].copy()\n",
    "# y_pred_test = neigh_model_final.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.drop(columns=['added_time','postcode','energy_label','subtype','bedrooms','id','index','price']).copy(),test['price'].copy()\n",
    "dtest = xgb.DMatrix(X_test, enable_categorical=True)\n",
    "\n",
    "y_pred_test=xgb_regressor_final.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error_1=(y_pred_test/y_test-1).mean()\n",
    "error_bound_1 = (y_pred_test/y_test-1).std()/len(y_pred_test)**(1/2)*1.96\n",
    "\n",
    "mean_error_2=abs(y_pred_test/y_test-1).mean()\n",
    "error_bound_2 = abs(y_pred_test/y_test-1).std()/(len(y_pred_test)**(1/2))*1.96\n",
    "\n",
    "mean_error_3=((y_pred_test-y_test)**2).mean()**(1/2)\n",
    "error_bound_3 = abs(y_pred_test-y_test).std()/(len(y_pred_test)**(1/2))*1.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = pd.DataFrame()\n",
    "y_pred_final['id']=test['id']\n",
    "y_pred_final['lower']=y_pred_test*(1-mean_error_1-error_bound_1)\n",
    "y_pred_final['upper']=y_pred_test*(1-mean_error_1+error_bound_1)\n",
    "y_pred_final['pred']=y_pred_test*(1-mean_error_1)\n",
    "\n",
    "y_pred_final.to_csv(f\"xgb_simple_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = pd.DataFrame()\n",
    "y_pred_final['id']=test['id']\n",
    "y_pred_final['lower']=y_pred_test*(1-mean_error_2-error_bound_2)\n",
    "y_pred_final['upper']=y_pred_test*(1+mean_error_2+error_bound_2)\n",
    "y_pred_final['pred']=y_pred_test\n",
    "\n",
    "y_pred_final.to_csv(f\"xgb_simple_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = pd.DataFrame()\n",
    "y_pred_final['id']=test['id']\n",
    "y_pred_final['lower']=np.maximum(y_pred_test-mean_error_3-error_bound_3,0)\n",
    "y_pred_final['upper']=y_pred_test+mean_error_3+error_bound_3\n",
    "y_pred_final['pred']=y_pred_test\n",
    "\n",
    "y_pred_final.to_csv(f\"xgb_simple_3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
